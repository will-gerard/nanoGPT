{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac21fa4a-2cb7-434a-b035-594ff2f645fc",
   "metadata": {},
   "source": [
    "# Transfer Learning with GPT2 Experiments\n",
    "\n",
    "I'm going to track some initial experiments trying to apply transfer learning to a pretrained GPT2 model to then use the final output for Automatic Short Answer Grading. In a meeting on 4/28 Mingyu and I played with the nanogpt repo and got a good sense of how it seems to be working, so the updates we need to make to attempt this seem pretty clear. The steps I am going to try to complete in this notebook are as follows:\n",
    "\n",
    "1. Figure out how to load in a pretrained model from a checkpoint file. He trained one for about 3 days on a server he has access to, so that is what we want to start with.\n",
    "2. Make sure the weights of the existing layers are frozen, so that we don't have to accumulate gradients and make updates on the ~10 million (I think?) weights in the nanoGPT model.\n",
    "3. Download the edited Mohler dataset and split into training and testing sets.\n",
    "4. Modify the network to prepare for transfer learning. One new MLP layer needs to be added, We are going to attempt this in two separate ways, and compare what is best. The first step here is to add a new layer to the network, I'll start with a simple MLP the same way Karpathy does it. The current forward function then needs to take one extra step to pass the output from the last layer of the transformer through this extra MLP. Then we will make two separate updates:\n",
    "    a. In the forward function, split the input into two separate chunks, one for the desired response, and one for the student response. Feed each response separately into the transformer, and save the final hidden states that result for each. Use some sort of pytorch comparison or vector norm operation to compare the similarity of the two vectors, and use this similarity metric to make the actual output.\n",
    "    b. concatenate the question, the desired answer, and the student answer, with separator tokens in between, into one single input tensor. Feed this input into the forward function, which will be modified again to feed the output of the last transformer layer into our new MLP.\n",
    "5. We want to compare to the papers we were looking at, and so want to compute the root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10a35503-80d2-4a4d-8d82-4ea629c5be1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the full dataset is (2273, 7)\n",
      "Training set size:  1591\n",
      "Validation set size:  454\n",
      "Testing set size:  228\n",
      "        id                                           question   \n",
      "2204  12.8        What is the Euler tour traversal of a tree?  \\\n",
      "1320   8.3       How can you implement a stack with an array?   \n",
      "859    5.3  What is the number of operations for insertion...   \n",
      "408    2.7                 What is the role of a header-file?   \n",
      "629    3.7  What are the similarities between iteration an...   \n",
      "\n",
      "                                         desired_answer   \n",
      "2204  A walk around the tree, starting with the root...  \\\n",
      "1320  Keep the top of the stack toward the end of th...   \n",
      "859   N (the length of the array) operations achieve...   \n",
      "408   To store a class interface, including data mem...   \n",
      "629   They both involve repetition; they both have t...   \n",
      "\n",
      "                                         student_answer  score_me   \n",
      "2204  it starts node on the left of the root and the...       2.5  \\\n",
      "1320  Make an array, make the bottom at spot 0, make...       5.0   \n",
      "859   theta(n) the best case senario is that everyth...       5.0   \n",
      "408   Allow compiler to recognize the classes when u...       3.0   \n",
      "629   they both are able to do repetiive tasks. howe...       2.0   \n",
      "\n",
      "      score_other  score_avg  \n",
      "2204         3.75      3.125  \n",
      "1320         4.00      4.500  \n",
      "859          4.00      4.500  \n",
      "408          4.00      3.500  \n",
      "629          5.00      3.500  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"mohler_dataset_edited.csv\")\n",
    "\n",
    "print(f\"the size of the full dataset is {data.shape}\")\n",
    "\n",
    "# Split the DataFrame into training, validation, and testing sets\n",
    "train, validate, test = np.split(data.sample(frac=1, random_state=42), [int(.7*len(data)), int(.9*len(data))])\n",
    "\n",
    "# Print the sizes of the resulting sets\n",
    "print(\"Training set size: \", len(train))\n",
    "print(\"Validation set size: \", len(validate))\n",
    "print(\"Testing set size: \", len(test))\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bc8025e-8c3e-4c77-9dd0-48b48dffc6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               question   \n",
      "2204        What is the Euler tour traversal of a tree?  \\\n",
      "1320       How can you implement a stack with an array?   \n",
      "859   What is the number of operations for insertion...   \n",
      "408                  What is the role of a header-file?   \n",
      "629   What are the similarities between iteration an...   \n",
      "\n",
      "                                         desired_answer   \n",
      "2204  A walk around the tree, starting with the root...  \\\n",
      "1320  Keep the top of the stack toward the end of th...   \n",
      "859   N (the length of the array) operations achieve...   \n",
      "408   To store a class interface, including data mem...   \n",
      "629   They both involve repetition; they both have t...   \n",
      "\n",
      "                                         student_answer  \n",
      "2204  it starts node on the left of the root and the...  \n",
      "1320  Make an array, make the bottom at spot 0, make...  \n",
      "859   theta(n) the best case senario is that everyth...  \n",
      "408   Allow compiler to recognize the classes when u...  \n",
      "629   they both are able to do repetiive tasks. howe...  \n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# So want to transform this data into X, Y pairs\n",
    "# Each X will be the (question, desired_answer, student_answer)\n",
    "# Y will be the corresponding score_avg\n",
    "# Define a list of column names to select\n",
    "selected_cols = ['question', 'desired_answer', 'student_answer']\n",
    "\n",
    "# same process function as in prepare.py for the openweb dataset, I'm guessing we want the format to be the same?\n",
    "# this time just take in the text directly\n",
    "# and output the encod\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "def process(text):\n",
    "    ids = enc.encode_ordinary(text) # encode_ordinary ignores any special tokens\n",
    "    ids.append(enc.eot_token) # add the end of text token, e.g. 50256 for gpt2 bpe\n",
    "    # note: I think eot should be prepended not appended... hmm. it's called \"eot\" though...\n",
    "    return ids\n",
    "\n",
    "# process each of the columns we care about in the dataframe\n",
    "# Apply the process function to each element of the selected columns\n",
    "x_df = train[selected_cols]\n",
    "print(x_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42dfc8be-8d83-4262-bb6a-60fe8a4614b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question                What is the Euler tour traversal of a tree?\n",
      "desired_answer    A walk around the tree, starting with the root...\n",
      "student_answer    it starts node on the left of the root and the...\n",
      "Name: 2204, dtype: object\n",
      "question          [2061, 318, 262, 412, 18173, 4205, 33038, 282,...\n",
      "desired_answer    [32, 2513, 1088, 262, 5509, 11, 3599, 351, 262...\n",
      "student_answer    [270, 4940, 10139, 319, 262, 1364, 286, 262, 6...\n",
      "Name: 2204, dtype: object\n",
      "First element of first tuple of x tuples: tensor([ 2061,   318,   262,   412, 18173,  4205, 33038,   282,   286,   257,\n",
      "         5509,    30, 50256])\n",
      "Second element of first tuple of x tuples: tensor([   32,  2513,  1088,   262,  5509,    11,  3599,   351,   262,  6808,\n",
      "           11,   810,  1123, 10139,   318,  1775,  1115,  1661,    25,   422,\n",
      "          262,  1364,    11,   422,  2174,    11,   422,   262,   826,    13,\n",
      "        50256])\n",
      "Third element of first tuple of x tuples: tensor([  270,  4940, 10139,   319,   262,  1364,   286,   262,  6808,   290,\n",
      "          788, 15740,   284, 11864,  1123, 10139,   287,   257,  1364,   284,\n",
      "          826,  1502,    11, 11864,   262,  6808,    11,   290,   788, 15740,\n",
      "          284,  9585,   262,  2180,  2239,   319,   262,   826,  1735,   286,\n",
      "          262,  5509,    13, 50256])\n",
      "In total we have 1591 tuples in the training set\n"
     ]
    }
   ],
   "source": [
    "# # He has some fancy concatenation thing, writing this all to a file, its a little confusing\n",
    "# # our dataset is small, I'm not going to worry about it, and will create tensors directly\n",
    "\n",
    "first_row = x_df.iloc[0]\n",
    "print(first_row)\n",
    "encoded_input = []\n",
    "encoded_dataframe = x_df.applymap(process)\n",
    "encoded_dataframe.head()\n",
    "\n",
    "first_row = encoded_dataframe.iloc[0]\n",
    "print(first_row)\n",
    "\n",
    "X_tuples = []\n",
    "for index, row in encoded_dataframe.iterrows():\n",
    "    # convert to numpy arrays\n",
    "    # np_arr_question = np.array(row['question'])\n",
    "    # np_arr_desired_answer = np.array(row['desired_answer'])\n",
    "    # np_arr_student_answer = np.array(row['student_answer'])\n",
    "    question_tensor = torch.tensor(row['question'], dtype=torch.int64)\n",
    "    desired_answer_tensor = torch.tensor(row['desired_answer'], dtype=torch.int64)\n",
    "    student_answer_tensor = torch.tensor(row['student_answer'], dtype=torch.int64)\n",
    "    X_tuples.append((question_tensor, desired_answer_tensor, student_answer_tensor))\n",
    "\n",
    "# sanity check to make sure this worked correctly\n",
    "# the three elements should be the encoded question, desired_answer, and student answer. Each should end with the end token\n",
    "print(f\"First element of first tuple of x tuples: {X_tuples[0][0]}\")\n",
    "print(f\"Second element of first tuple of x tuples: {X_tuples[0][1]}\")\n",
    "print(f\"Third element of first tuple of x tuples: {X_tuples[0][2]}\")\n",
    "\n",
    "print(f\"In total we have {len(X_tuples)} tuples in the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "62246727-3626-40af-90d0-c094d7011b21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1591,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now get the average scores, which will be our y values\n",
    "Y = np.array(train['score_avg'])\n",
    "Y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
